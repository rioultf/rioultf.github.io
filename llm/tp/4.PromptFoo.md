---
author:
- François Rioult
lang: fr
title: Application des LLM 
subtitle: TP : PromptEngineering `PromptFoo`
---

`PromptFoo` permet d'automatiser les requêtes sur une API `chat_completions`.

Un fichier de configuration `promptfooconfig.yaml` définit :

* une liste de prompts : ici un prompt dans un fichier JSON : 

```
[
  {
    "role": "user",
    "content": "Consider the content of the following email. <email>{{file}}</email>. What is the language used in the email? Answer with only one word."
  }
]
```

* une liste de providers, ici `LMStudio`

* une configuration par défaut `defaultTest`

* une liste de tests : liste de variables instanciées dans le prompt

[promptfooconfig.yaml](script/promptFoo/promptfooconfig.yaml)

```yaml
# yaml-language-server: $schema=https://promptfoo.dev/config-schema.json
description: "My eval"

prompts:
  #- 'Consider the content of the following email. <email>{{file}}</email>. What is the language used in the email? Answer with only one word.'
  - file://prompt.json


providers:
  - id: openrouter:openai/gpt-3.5-turbo

  - id: https
    config:
      url: 'http://0.0.0.0:1234/v1/chat/completions'
      method: 'POST'
      body:
        model: 'smollm2-1.7b-instruct'
        messages: '{{prompt}}'
      transformResponse: 'json.choices[0].message.content'
      maxTokens: 300

tests:
  - vars:
      file: file://data/mail1.txt
  - vars:
      file: file://data/mail2.txt
```

Il s'agit de la définition d'un template assemblant différents fichiers (tous les constituants peuvent être mis dans des fichiers). Couplé avec un gestionnaire de version, la dépendance forte de `PromptFoo` lui confère une traçabilité optimale.

Deux commandes sont alors disponibles :

* `npx promptfoo eval --no-cache` : pour chaque prompt, exécute les différents configurations de test sur chaque provider. Il faut déactiver le cache pour forcer l'interrogation du modèle.

```
$ npx promptfoo eval --no-cache
Cache is disabled.
Starting evaluation eval-nEV-2025-12-18T17:37:13
Running 4 test cases (up to 4 at a time)...
Evaluating [████████████████████████████████████████] 100% | 4/4 | http://0.0.0.0:1234/v1/chat/completit

┌───────────────────────────────┬───────────────────────────────┬───────────────────────────────┐
│ file                          │ [openrouter:openai/gpt-3.5-t… │ [http://0.0.0.0:1234/v1/chat… │
│                               │ prompt.json:                  │ prompt.json:                  │
│                               │ [{"role":"user","content":"C… │ [{"role":"user","content":"C… │
│                               │ the content of the following  │ the content of the following  │
│                               │ email.                        │ email.                        │
│                               │ <email>{{file}}</email>. What │ <email>{{file}}</email>. What │
│                               │ is the language used in the   │ is the language used in the   │
│                               │ email? Answer with only one   │ email? Answer with only one   │
│                               │ word."}]                      │ word."}]                      │
├───────────────────────────────┼───────────────────────────────┼───────────────────────────────┤
│ file://data/mail1.txt         │ [PASS] English                │ [PASS] French                 │
├───────────────────────────────┼───────────────────────────────┼───────────────────────────────┤
│ file://data/mail2.txt         │ [PASS] French                 │ [PASS] French                 │
└───────────────────────────────┴───────────────────────────────┴───────────────────────────────┘
==============================================================================================
✔ Evaluation complete. ID: eval-nEV-2025-12-18T17:37:13

» Run promptfoo view to use the local web viewer
» Do you want to share this with your team? Sign up for free at https://promptfoo.app
» This project needs your feedback. What's one thing we can improve? https://promptfoo.dev/feedback
==============================================================================================
Token Usage Summary:

  Evaluation:
    Total: 2 961
    Prompt: 2 959
    Completion: 2

  Provider Breakdown:
    openrouter:openai/gpt-3.5-turbo: 2 961 (2 requests)
      (2 959 prompt, 2 completion)

  Grand Total: 2 961 tokens
==============================================================================================
Duration: 1m 57s (concurrency: 4)
Successes: 4
Failures: 0
Errors: 0
Pass Rate: 100.00%
==============================================================================================
```



* `npx promptfoo view` : lance une [interface web](http://localhost:15500/eval) permettant d'analyser les résultats dans le cache.

Le cache est une base de données de prompts / réponses, accompagnés des fichiers de configuration. Ceux peuvent être édités de manière à relancer le test.


# Intégration `OpenRouter`

[Source](https://www.promptfoo.dev/docs/providers/openrouter/)

        # source ~/svn/llm/md/script/.env





On peut définir des [prompts comme des fonctions .py ou .js](https://www.promptfoo.dev/docs/configuration/parameters/#prompt-functions)

De nombreuses métriques sont disponibles, déterministes ou fournies par des LLM : Model-graded metrics. 

llm-rubric is promptfoo's general-purpose grader for "LLM as a judge" evaluation. Propose également de la classification, modération, etc.

#### Cas d'usage

Le système de base construit un tableau test/prompt.

* tester différents prompts : sur différentes formulations d'une tâche, par exemple de traduction ou de rédaction. C'est le cas d'usage par défaut, il suffit pour cela de définir plusieurs prompts.
* tester différents system prompts : il faut définir autant de cas de test que nécessaire (voir ci-dessous)
* tester différents paramètres du modèle : autant de cas de tests

Utilisation du system de template analogue à `jinja2` : [nunjucks](https://www.promptfoo.dev/docs/configuration/parameters/#nunjucks-filters)

#### Prompt pour chat

Certains modèles une interaction sous forme de messages, avec un role et un contenu. On pourra définir les prompts dans des fichiers JSON :

```json
[
    {
      "role": "system",
      "content": "{{systemPrompt}}"
    },
    {
      "role": "user",
      "content": "Tell me about planets"
    }
]
```

<!--------------------------------------------------------------->
### Notes

* [Promptfoo: A Test-Driven Approach to LLM Success](https://medium.com/@fassha08/promptfoo-a-test-driven-approach-to-llm-success-154a444b2669)

* [Le postman des llm, mais pas de modèle local](https://www.adaline.ai/get-started)

* [Des exemples dans Postman](https://www.postman.com/manukmcts/llm/overview)
* [Génératon de tests Postman par LLM](https://www.aimodels.fyi/papers/arxiv/automating-rest-api-postman-test-cases-using)

* [An Overview on Testing Frameworks For LLMs](https://llmshowto.com/blog/llm-test-frameworks)
* [Tester avec l’IA générative – Stratégie & Feuille de route réaliste](https://www.smartesting.com/tester-avec-lia-generative-strategie-feuille-de-route-realiste/)
* LLMops [Automated Testing for LLMOps](https://www.deeplearning.ai/short-courses/automated-testing-llmops/)

# Limites

* comment utiliser `PromptFoo` uniquement pour générer la liste des requêtes ?
