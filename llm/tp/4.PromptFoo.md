---
author:
- François Rioult
lang: fr
title: Application des LLM 
subtitle: TP : PromptEngineering `PromptFoo`
---

`PromptFoo` permet d'automatiser les requêtes sur une API `chat_completions`.

Un fichier de configuration `promptfooconfig.yaml` définit :

* une liste de prompts : ici un prompt dans un fichier JSON : 

```
[
  {
    "role": "user",
    "content": "Consider the content of the following email. <email>{{file}}</email>. What is the language used in the email? Answer with only one word."
  }
]
```

* une liste de providers, ici `LMStudio`

* une configuration par défaut `defaultTest`

* une liste de tests : liste de variables instanciées dans le prompt



```yaml
# yaml-language-server: $schema=https://promptfoo.dev/config-schema.json
description: "My eval"

prompts:
  #- 'Consider the content of the following email. <email>{{file}}</email>. What is the language used in the email? Answer with only one word.'
  - file://prompt.json


providers:
#  - id: openai:chat:gpt-3.5-turbo

  - id: https
    config:
      url: 'http://0.0.0.0:1234/v1/chat/completions'
      method: 'POST'
      body:
        model: 'smollm2-1.7b-instruct'
        messages: '{{prompt}}'
      transformResponse: 'json.choices[0].message.content'
      maxTokens: 300

tests:
  - vars:
      file: file://data/mail1.txt
  - vars:
      file: file://data/mail2.txt```

Il s'agit de la définition d'un template assemblant différents fichiers (tous les constituants peuvent être mis dans des fichiers). Couplé avec un gestionnaire de version, la dépendance forte de `PromptFoo` lui confère une traçabilité optimale.

Deux commandes sont alors disponibles :

* `npx promptfoo eval --no-cache` : pour chaque prompt, exécute les différents configurations de test sur chaque provider. Il faut déactiver le cache pour forcer l'interrogation du modèle.

```
$ npx promptfoo eval --no-cache
Cache is disabled.
Starting evaluation eval-5FZ-2025-12-18T17:02:18
Running 2 test cases (up to 4 at a time)...
Evaluating [████████████████████████████████████████] 100% | 2/2 | http://0.0.0.0:1234/v1/chat/completit

┌───────────────────────────────────────────────┬───────────────────────────────────────────────┐
│ file                                          │ [http://0.0.0.0:1234/v1/chat/completions]     │
│                                               │ prompt.json:                                  │
│                                               │ [{"role":"user","content":"Consider the       │
│                                               │ content of the following email.               │
│                                               │ <email>{{file}}</email>. What is the language │
│                                               │ used in the email? Answer with only one       │
│                                               │ word."}]                                      │
├───────────────────────────────────────────────┼───────────────────────────────────────────────┤
│ file://data/1.txt                             │ [PASS] French                                 │
├───────────────────────────────────────────────┼───────────────────────────────────────────────┤
│ file://data/2.txt                             │ [PASS] French                                 │
└───────────────────────────────────────────────┴───────────────────────────────────────────────┘
==============================================================================================
✔ Evaluation complete. ID: eval-5FZ-2025-12-18T17:02:18

» Run promptfoo view to use the local web viewer
» Do you want to share this with your team? Sign up for free at https://promptfoo.app
» This project needs your feedback. What's one thing we can improve? https://promptfoo.dev/feedback
==============================================================================================
Duration: 2m 51s (concurrency: 4)
Successes: 2
Failures: 0
Errors: 0
Pass Rate: 100.00%
==============================================================================================
```



* `npx promptfoo view` : lance une interface web permettant d'analyser les résultats dans le cache

Le cache est une base de données de prompts / réponses, accompagnés des fichiers de configuration. Ceux peuvent être édités de manière à relancer le test.

On peut définir des [prompts comme des fonctions .py ou .js](https://www.promptfoo.dev/docs/configuration/parameters/#prompt-functions)

De nombreuses métriques sont disponibles, déterministes ou fournies par des LLM : Model-graded metrics. 

llm-rubric is promptfoo's general-purpose grader for "LLM as a judge" evaluation. Propose également de la classification, modération, etc.

#### Cas d'usage

Le système de base construit un tableau test/prompt.

* tester différents prompts : sur différentes formulations d'une tâche, par exemple de traduction ou de rédaction. C'est le cas d'usage par défaut, il suffit pour cela de définir plusieurs prompts.
* tester différents system prompts : il faut définir autant de cas de test que nécessaire (voir ci-dessous)
* tester différents paramètres du modèle : autant de cas de tests

Utilisation du system de template analogue à `jinja2` : [nunjucks](https://www.promptfoo.dev/docs/configuration/parameters/#nunjucks-filters)

#### Prompt pour chat

Certains modèles une interaction sous forme de messages, avec un role et un contenu. On pourra définir les prompts dans des fichiers JSON :

```json
[
    {
      "role": "system",
      "content": "{{systemPrompt}}"
    },
    {
      "role": "user",
      "content": "Tell me about planets"
    }
]
```

<!--------------------------------------------------------------->
### Notes

* [Promptfoo: A Test-Driven Approach to LLM Success](https://medium.com/@fassha08/promptfoo-a-test-driven-approach-to-llm-success-154a444b2669)

* [Le postman des llm, mais pas de modèle local](https://www.adaline.ai/get-started)

* [Des exemples dans Postman](https://www.postman.com/manukmcts/llm/overview)
* [Génératon de tests Postman par LLM](https://www.aimodels.fyi/papers/arxiv/automating-rest-api-postman-test-cases-using)

* [An Overview on Testing Frameworks For LLMs](https://llmshowto.com/blog/llm-test-frameworks)
* [Tester avec l’IA générative – Stratégie & Feuille de route réaliste](https://www.smartesting.com/tester-avec-lia-generative-strategie-feuille-de-route-realiste/)
* LLMops [Automated Testing for LLMOps](https://www.deeplearning.ai/short-courses/automated-testing-llmops/)
