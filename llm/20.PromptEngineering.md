---
author:
- François Rioult
lang: fr
title: Application des LLM
subtitle: Prompt Engineering
---

Le *prompt engineering* consiste à déterminer le prompt adéquat pour la tâche à réaliser.

Avant toute chose, il importe de comprendre que cette tâche requiert de dialoguer avec une *boîte noire*, en langue naturelle -- et éventuellement quelques formatages --. On ne connaît pas exactement le fonctionnement de cette boîte noire.

À la différence de tout ce que l'on connaît en science informatique *déterministe*, où chaque action mène toujours à la même conséquence, il faut ici inventer une méthode de développement pour parvenir à *programmer* le LLM.

# Environnement de développement

Un environnement de développement doit rassurer le programmeur en étant le plus neutre et déterministe possible. À ce titre, les modèles en ligne type `chatGPT` sont à exclure. Ils mémorisent en effet bien trop d'[information sur les interactions passées](https://www.reddit.com/r/ChatGPT/comments/1co8qtr/how_is_latest_chatgpt_feature_memory_implemented/).

Il faut également être prudent avec les interfaces type `open-webui` et bien comprendre leur fonctionnement en mode *multi-turn*, en analysant les logs. Par exemple, la retranscription du chat ci-dessous est à comparer avec ce qui est transmis à l'API :

```
### USER
Quel âge a Tom ?

### ASSISTANT
Je ne sais pas, pouvez-vous me donner plus d'information sur Tom afin que je puisse déterminer son âge ?

### USER
Tom a 7 ans.

### ASSISTANT
Tom a 7 ans.

### USER
Quel âge a Tom ?

### ASSISTANT
Tom a 7 ans.
```

Lors de la dernière requête, c'est l'intégralité de la conversation qui est transmise :

```json
{
        "id": ...
        "role": "user",
        "content": "Quel âge a Tom ?",
        "timestamp": ...
    },
    {
        ...
        "role": "assistant",
        "content": "Je ne sais pas, pouvez-vous me donner plus d\"information sur Tom afin que je puisse déterminer son âge ?",
        ...
    },
    {
        "role": "user",
        "content": "Tom a 7 ans.",
    },
    {
        "role": "assistant",
        "content": "Tom a 7 ans.",
    },
    {
        "role": "user",
        "content": "Quel âge a Tom ?",
    }
]
```

La dernière réponse est donc le résultat de toute la conversation, qui vient peu à peu remplir la fenêtre de contexte.

## Recommandations

* travailler avec une API performante
* explorer les capacités du modèle en terme de mémorisation, raisonnement, contextualisation, paramétrage
* gérer ses itérations sous forme de fichiers versionnés -> PromtFoo

<!------------------------------------------------------->
<!------------------------------------------------------->
<!------------------------------------------------------->
# Capacités du modèle

Les expériences relatées ci-dessous ont été effectuées avec `gpt3.5`. On pourrait longuement discuter du choix de ce modèle. Rappelons que ce cours est destiné à des étudiants en Licence Pro IA, qu'ils vont travailler avec des modèles performants. On peut bien sûr retravailler ces tests avec des modèles locaux et légers.

## Psychologie d'un LLM

Le socle de l’étude de la pensée en psychologie permet d’appréhender comment l’esprit humain transforme l’information en action et en création. On l'adapte ici à l'interaction avec le modèle, selon les points suivants :

- **mémoire** : stockage et récupération de l'information, base de la pensée ;
- **raisonnement logique** : capacité à manipuler l'information, déduire et résoudre des problèmes ;
- **contextualisation** : adaptation et intégration des informations en fonction du contexte ;
- **flexibilité cognitive** : ajustement dynamique du traitement de l'information ;
- **synthèse** : manipulation et structuration des données pour en extraire l'essentiel ;
- **créativité** : production d'idées et de solutions originales ;
- **méta-cognition** : Supervision et régulation des processus de pensée.

Bien qu'un LLM n'ait pas d'esprit, il interagit textuellement avec une personne qui utilise ce mode de pensée. Ce cadre fournit une grille de lecture des capacités du modèle.

<!------------------------------------------------------->
## Mémorisation

Le modèle a une mémoire, incarnée par le *contexte*. [Cette taille dépend du modèle utilisé](https://agi-sphere.com/context-length/), de $4k* tokens pour  GPT3.5 et Llama2 à $4 k$ tokens pour GPT-4.

```
### USER
Quel âge a Tom ?

### ASSISTANT
Je ne sais pas, pouvez-vous me donner plus d'information sur Tom afin que je puisse déterminer son âge ?

### USER
Tom a 7 ans.

### ASSISTANT
Tom a 7 ans.

### USER
Quel âge a Tom ?

### ASSISTANT
Tom a 7 ans.
```

Je n'ai pas trouvé moyen d'afficher la taille du contexte dans `open-webui`, `LM-studio` le fait.

<!------------------------------------------------------->
## Opérations

[Dans une certaine mesure](https://loeber.substack.com/p/21-everything-we-know-about-llms), les modèles sont capables de faire du calcul. C'est une certaine forme de raisonnement qu'on n'attendait pas d'un modèle de langue. Les éléments manipulés ne suivent pas un raisonnement mathématique mais plutôt guidé par un fragment de texte.

```
### USER
dans un an, quel âge aura-t-il ?

### ASSISTANT
Dans un an, Tom aura huit ans.

### USER
dans combien de temps aura-t-il le droit de conduire une voiture ?

### ASSISTANT
En supposant que l'âge légal pour conduire une voiture est de 18 ans, Tom pourra conduire une voiture dans 11 ans.

### USER
si l’âge légal était de 6 ans, dans combien de temps pourrait-il conduire ?

### ASSISTANT
S'il était légal de conduire une voiture à l'âge de 6 ans, Tom pourrait déjà conduire, car il a actuellement 7 ans.
```

<!------------------------------------------------------->
## Raisonnement

Un LLM est capable de raisonnement logique :

```
### USER
Si quelqu’un possède un ticket, il peut prendre le bus. Tom a un ticket. Peut-il prendre le bus ?

### ASSISTANT
Oui, Tom peut prendre le bus car il possède un ticket.

### USER
Max n’a pas les moyens d’acheter un titre de transport. Peut-il prendre le bus ?

### ASSISTANT
Non, Max ne peut pas prendre le bus s'il n'a pas les moyens d'acheter un titre de transport.
```

Ci-dessous quelques interactions issues de syllogismes (*Les dossiers de la recherche*, Août-Septembre 2013 - n°5).

```
### USER
supposons que la plupart des Zolgos de charles sont sans Faltrak et que Marchize est un des Zolgos de Charles. Peut-on en déduire que Marchize n’a pas de Faltrak ?

### ASSISTANT
Non, on ne peut pas en être certain. Même si la plupart des Zolgos de Charles n'ont pas de Faltrak, cela ne signifie pas que tous les Zolgos de Charles sont sans Faltrak. Donc, il est possible que Marchize ait un Faltrak même si la plupart des Zolgos de Charles n'en ont pas.

### USER
Si certains Pallios sont très fructueux et si les Fiermy ne sont pas très fructueux, peut-on en déduire qu’aucun Pallio ne peut être un Fiermy ?

### ASSISTANT
Non, on ne peut pas en déduire cela. Le fait que certains Pallios soient très fructueux et que les Fiermy ne soient pas très fructueux ne signifie pas nécessairement que aucun Pallio ne peut être un Fiermy. Il est possible qu'il existe des Pallios qui sont très fructueux tout en étant également des Fiermy, bien que ce soit moins commun.

### USER
Si tous les maxars de Louis ont au moins cinq felous et si certains maxars de Louis sont des bruix, peut-on en déduire que certains bruix ont plus de quatre felous ?

### ASSISTANT
Oui, on peut effectivement en déduire que certains bruix ont plus de quatre felous. Si tous les maxars de Louis ont au moins cinq felous et que certains maxars de Louis sont des bruix, alors il est logique de conclure que certains bruix ont plus de quatre felous, puisque tous les maxars ont au moins cinq felous.

### USER
Si Solian fractionne tous les nano-bractères et si Solian est duplicain, peut-on en déduire que les nano-bractères sont toujours fractionnés par un duplicain ?

### ASSISTANT
Oui, si Solian fractionne tous les nano-bractères et que Solian est duplicain, alors on peut en effet en déduire que les nano-bractères sont toujours fractionnés par un duplicain. Puisque c'est Solian, qui est duplicain, qui effectue systématiquement le fractionnement des nano-bractères, cela implique que ce processus est toujours effectué par un duplicain.

### USER
Si les bouzous qui ne savent pas looder sont miagres et si Clovis a acheté un bouzou et s’il s’en sert pour looder, alors peut-on en déduire que le bouzou de Clovis est miagre ?

### ASSISTANT
Non, on ne peut pas en déduire que le bouzou de Clovis est miagre. Le fait que les bouzous qui ne savent pas looder sont miagres ne signifie pas automatiquement que tous les bouzous qui loodent ne sont pas miagres. Donc, même si Clovis utilise son bouzou pour looder, cela ne permet pas de conclure que son bouzou est miagre.
```

On notera que ces exercices ne sont pas élémentaires d'un point de vue de la *logique*. Il faut être capable de manipuler les formalismes de la logique d'ordre 1 avec les quantificateurs existentiels et universels. 

Le modèle s'en sort bien et conjugue lui-même les verbes ! On comprendra bien sûr qu'il n'effectue aucune manipulation formelle, ne résout aucun équation. Il faut coller sa réponse à des éléments qu'il a déjà vus et prédit la suite *naturelle*, qui s'avère être la bonne réponse d'un point de vue logique.

On ne méfiera de son emphase potentielle. En effet, il répond : 

        Il est possible qu'il existe des Pallios qui sont très fructueux tout en étant également des Fiermy, -> OK
        bien que ce soit moins commun. -> KO

Dans ce cadre, l'intérêt d'un modèle de langue sachant raisonner est palpable : il sera capable de traiter des tournures vagues et diverses.

Il reste à beaucoup expérimenter pour analyser finement les réactions du modèle. Cependant, il importe de rester conscient des interprétations potentielles des concepts exprimés dans les prompts. Dans les exemples précédant, les concepts n'ont pas d'identité propre, et le modèle peut les manipuler sans *a priori*. Lorsqu'il a des connaissances propres sur de nombreux sujets, il est beaucoup plus délicat de cerner les limites et les biais du raisonnement.

En marge de la gestion de la connaissance *a priori* du modèle, la conception des interactions pose de nombreuses questions sur la neutralité et l'orientation d'une question. Ces problématiques ressurgissent lorsque l'on développe un modèle faisant appel à des outils externes : il faut inventer des questions auquelles seul l'outil peut répondre. Et le problème c'est que le modèle est très performant et peut déjà disposer d'outils.

Enfin, je n'ai pas abordé ici le raisonnement au sens plus récent du terme, avec l'apparition de modèles comme `o1` ou `deepseek`. Ce raisonnement inclut le développement du prompt en multiples chaînes de pensée. Voir le [chapitre dédié]().

<!------------------------------------------------------->
## Contextualisation / personnalisation

Tester si le chatbot peut adopter un rôle spécifique et répondre en accord avec ce personnage. Évaluer comment le chatbot gère des instructions conditionnelles et peut adapter sa réponse en fonction des conditions données.

```
### USER
salue-moi cordialement

### ASSISTANT
Bonjour, je te salue cordialement.

### USER
salue-moi vulgairement

### ASSISTANT
Désolé, je ne peux pas répondre à cette demande.

### USER
salue-moi fraternellement

### ASSISTANT
Salut, frère!
```

<!------------------------------------------------------->
## Manipulation de données et synthèse d’informations

```
### USER
Voici une liste de chiffres : 12, 45, 67, 89. Peux-tu calculer leur moyenne et me donner une synthèse de ce que cela représente ?

### ASSISTANT
La moyenne des chiffres 12, 45, 67, et 89 est de :

(12 + 45 + 67 + 89) / 4 = 53.25

Cela représente que la valeur moyenne de ces chiffres est de 53.25. Cela peut être utilisé pour avoir une idée générale de la tendance des chiffres donnés.

### USER
Quelle est la tendance ?

### ASSISTANT
La tendance des chiffres 12, 45, 67, et 89 est à la hausse, car la moyenne est de 53.25, ce qui est supérieur à la moyenne des chiffres individualisés. Cela signifie que les chiffres plus élevés (67 et 89) ont plus de poids dans la moyenne, ce qui indique une tendance à la hausse.
```

Il faut être très prudent avec les manipulations de données !

<!------------------------------------------------------->
# Prompt Engineering

On peut considérer le prompt engineering comme *crucial*. Par exemple, ajouter "Let's think step by step" au prompt [booste les capacités arithmétiques du modèle](https://arxiv.org/pdf/2205.11916).

Le prompt engineering est également un art en voie de disparition :

> Just go out and write shit. When it doesn’t work, troubleshoot. Then ask the LLM what you should be doing differently to accomplish your goal. It just works, man. [Source](https://www.reddit.com/r/PromptEngineering/comments/1iig4g9/is_learn_prompting_worth_it/)


On s'efforcera de respecter [quelques principes](https://natesnewsletter.substack.com/p/your-pocket-guide-to-prompt-engineering) :

* définir un rôle (*persona*) pour indiquer au modèle qui il est supposé être
* définir un but 
* préciser le contexte, les points clés que le modèle doit prendre en compte
* définir le format de la réponse

On trouve de nombreuses variations de ces concepts, par ex. [Risen Framework](https://beeazt.com/knowledge-base/prompt-frameworks/the-risen-framework/). Ces techniques sont nommées [*framework de rédaction*](https://www.reddit.com/r/ChatGPTPromptGenius/comments/1haj8zd/the_top_secrets_to_master_prompt_engineering/). 

<!------------------------------------------------------->
## Techniques de prompt

D'après le site de référence, très pédagogique: <https://www.promptingguide.ai/fr/introduction>.

Un *shot* (tir, coup) désigne une tentative de prompt précédent le prompt courant. Les techniques élémentaires différencient le *zero-shot* du *few-shot* :

* *zero-shot* : aucun prompt avant le prompt courant, le contexte est vide
* *few-shot* : on a effectué des prompts préliminaires, qui ont servi d'[exemple](https://www.promptingguide.ai/fr/techniques/fewshot).

Citons quelques techniques plus élaborées :

* *chain-of-thought* : expliciter la *chaîne de pensée* que doit considérer le modèle. Des détails [ici](https://www.reddit.com/r/PromptEngineering/comments/1j0esuw/chain_of_thot_custom_gpt_training_doc/).
* *Retrieve Augmented Generation - RAG* : une base de connaissances est préalablement interrogée selon le prompt pour *améliorer la génération par récupération*.

<!------------------------------------------------------->
# Métacognition

La *métacognition* est la capacité à réfléchir sur ses propres processus cognitifs. Le préfixe *meta* indique qu'on monte d'un niveau dans l'abstraction. 

Il est pertinent d'utiliser ces techniques pour améliorer la compréhension de la requête : [Metacognitive prompting improves understanding in large language models](https://arxiv.org/pdf/2308.05342).

* [De nombreux exemples détaillés](https://www.reddit.com/r/ChatGPTPromptGenius/comments/1j1pekn/toolbox_for_highlevel_thought_12_tools_try/)

<!------------------------------------------------------->
# Références

* [de bonnes définitions](https://www.spiceworks.com/tech/artificial-intelligence/articles/what-is-prompt-engineering/)
* [catalogue de prompts](https://arxiv.org/pdf/2302.11382)
* [super words](https://www.reddit.com/r/ChatGPTPromptGenius/comments/1gdqyog/super_words_implications_and_in_final_evolution/)
* (techniques de prompt avec LangChain)[https://github.com/NirDiamant/Prompt_Engineering]

https://medium.com/aiguys/the-prompt-report-prompt-engineering-techniques-254464b0b32b
